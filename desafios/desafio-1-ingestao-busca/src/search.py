import os
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_postgres import PGVector
from langchain_core.prompts import ChatPromptTemplate

load_dotenv()

PROMPT_TEMPLATE = """
CONTEXTO:
{contexto}

REGRAS:
- Responda somente com base no CONTEXTO.
- Se a informa√ß√£o n√£o estiver explicitamente no CONTEXTO, responda:
  "N√£o tenho informa√ß√µes necess√°rias para responder sua pergunta."
- Nunca invente ou use conhecimento externo.
- Nunca produza opini√µes ou interpreta√ß√µes al√©m do que est√° escrito.

EXEMPLOS DE PERGUNTAS FORA DO CONTEXTO:
Pergunta: "Qual √© a capital da Fran√ßa?"
Resposta: "N√£o tenho informa√ß√µes necess√°rias para responder sua pergunta."

Pergunta: "Quantos clientes temos em 2024?"
Resposta: "N√£o tenho informa√ß√µes necess√°rias para responder sua pergunta."

Pergunta: "Voc√™ acha isso bom ou ruim?"
Resposta: "N√£o tenho informa√ß√µes necess√°rias para responder sua pergunta."

PERGUNTA DO USU√ÅRIO:
{pergunta}

RESPONDA A "PERGUNTA DO USU√ÅRIO"
"""

def validate_environment():
    required_vars = ["OPENAI_API_KEY", "PGVECTOR_URL", "PGVECTOR_COLLECTION"]
    for var in required_vars:
        if not os.getenv(var):
            raise RuntimeError(f"Environment variable {var} is not set")

def get_vector_store():
    validate_environment()
    
    embeddings = OpenAIEmbeddings(
        model=os.getenv("OPENAI_MODEL", "text-embedding-3-small")
    )
    
    store = PGVector(
        embeddings=embeddings,
        collection_name=os.getenv("PGVECTOR_COLLECTION"),
        connection=os.getenv("PGVECTOR_URL"),
        use_jsonb=True,
    )
    
    return store

def search_documents(query: str, k: int = 10):
    store = get_vector_store()
    
    results = store.similarity_search_with_score(query, k=k)
    
    if not results:
        return []
    
    return results

def format_context(results):
    if not results:
        return "Nenhuma informa√ß√£o relevante encontrada."
    
    context_parts = []
    for i, (doc, score) in enumerate(results, 1):
        context_parts.append(f"--- Documento {i} (relev√¢ncia: {score:.3f}) ---")
        context_parts.append(doc.page_content.strip())
        context_parts.append("")
    
    return "\n".join(context_parts)

def search_prompt(question=None):
    try:
        validate_environment()
        
        llm = ChatOpenAI(
            model="gpt-5-nano",
            temperature=0.1
        )
        
        prompt = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)
        
        chain = prompt | llm
        
        return chain
        
    except Exception as e:
        print(f"Erro ao inicializar o sistema de busca: {e}")
        return None

def get_answer(question: str):
    try:
        print("üîç Buscando documentos relevantes...")
        results = search_documents(question, k=10)
        
        if not results:
            return "N√£o tenho informa√ß√µes necess√°rias para responder sua pergunta."
        
        print(f"üìÑ Encontrados {len(results)} documentos relevantes")
        
        context = format_context(results)
        
        chain = search_prompt()
        if not chain:
            return "Erro ao processar a pergunta."
        
        print("ü§ñ Gerando resposta...")
        response = chain.invoke({
            "contexto": context,
            "pergunta": question
        })
        
        return response.content
        
    except Exception as e:
        print(f"Erro durante a busca: {e}")
        return "Ocorreu um erro ao processar sua pergunta."